{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sample_submission.csv', 'test.csv', 'train.csv']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import math\n",
    "import matplotlib.cm as cm \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "print(os.listdir(\"./input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"./input/train.csv\")\n",
    "test_data= pd.read_csv(\"./input/test.csv\")\n",
    "#separating labels and pixels\n",
    "train_labels=np.array(train_data.loc[:,'label'])\n",
    "train_data=np.array(train_data.loc[:,train_data.columns!='label'])\n",
    "#train_data=train_data/train_data.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c423f697f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAQGUlEQVR4nO3de4xUdZrG8edVgSiMKEurHYXtWVQY1jiMqeANJxhv4JVJnFESlTW6GCKJoxOzyv6h/CWrO463lQhKBleXccQRlRAVGY1CgrEgrYLuji4iIh1odMXLRh3k3T+62LTY9aumzqk6Be/3k3S6up46Xe/U+HCq61Sdn7m7AOz/Dih6AADNQdmBICg7EARlB4Kg7EAQlB0IgrIDQVB29MnMHjOzLjP73Mz+YmbXFj0TsjHeVIO+mNnfS3rf3b8xszGSXpF0gbuvKXYy1Is9O/rk7uvd/ZvdP1a+RhU4EjKi7KjKzB40s/+V9J+SuiQtK3gkZMDTeCSZ2YGSTpU0UdK/uPtfi50I9WLPjiR3/87dV0o6RtKMoudB/Sg7+usg8Tf7Po2y4wfM7Agzu9zMhpjZgWZ2nqSpkv5c9GyoH3+z4wfMrE3SYkk/Vc8O4UNJ97n7/EIHQyaUHQiCp/FAEJQdCIKyA0FQdiCIg5p5Z8OHD/eOjo5m3iUQysaNG7V9+3brK8tUdjObJOleSQdKetjd56Ru39HRoXK5nOUuASSUSqWqWd1P4yvvmf43SZMljZU01czG1vv7ADRWlr/Zx6vn884b3P1bSX+QdEk+YwHIW5ayHy3po14/b65c9z1mNt3MymZW7u7uznB3ALLIUva+XgT4wdvx3H2eu5fcvdTW1pbh7gBkkaXsmyWN6PXzMZK2ZBsHQKNkKfsbko4zsx+b2UBJl0t6Np+xAOSt7kNv7r7TzGZKekE9h94WuPv63CYDkKtMx9ndfZk4LxmwT+DtskAQlB0IgrIDQVB2IAjKDgRB2YEgKDsQBGUHgqDsQBCUHQiCsgNBUHYgCMoOBEHZgSAoOxAEZQeCoOxAEJQdCIKyA0FQdiAIyg4EQdmBICg7EARlB4Kg7EAQlB0IgrIDQVB2IAjKDgRB2YEgMi3ZbGYbJX0h6TtJO929lMdQAPKXqewVZ7r79hx+D4AG4mk8EETWsrukF81sjZlN7+sGZjbdzMpmVu7u7s54dwDqlbXsp7v7SZImS7rezH6+5w3cfZ67l9y91NbWlvHuANQrU9ndfUvl+zZJT0san8dQAPJXd9nNbLCZ/Wj3ZUnnSlqX12AA8pXl1fgjJT1tZrt/z3+4+/O5TBVMrdcy7r///mS+cuXKqtnLL79c10y7DRgwIJlfcMEFyXzMmDFVs9GjR9c1025TpkxJ5kOGDKmaHXRQHgei9i11/y929w2SfprjLAAaiENvQBCUHQiCsgNBUHYgCMoOBBHv+EOdtmzZUjVbunRpctvFixcn8+XLl9c1026DBg2qmnV0dGT63bt27UrmS5YsyfT7s7j66quT+bhx46pm06ZNS247c+bMZL4vHrpjzw4EQdmBICg7EARlB4Kg7EAQlB0IgrIDQex7BwsLkvooZ2dnZ6bfffHFFyfzCRMm1L191o+Rrl69OplPnDgxmd93331Vs/Hjs53r5PXXX0/mixYtqprdeOONyW23bt2azO+4445k3orYswNBUHYgCMoOBEHZgSAoOxAEZQeCoOxAEObuTbuzUqnk5XK5afeXp8cee6xq9sknnyS3rXW65WOPPbaumZrh+efTZwffvj29pucVV1yR5zh75csvv6yanXDCCcltDz300GS+Zs2aZF7rFNyNUiqVVC6Xra+MPTsQBGUHgqDsQBCUHQiCsgNBUHYgCMoOBMHn2fupyOPFRZo0aVJh97127dpknvq8uiTNnz+/arZjx47ktitWrEjmRR1Hz6Lmnt3MFpjZNjNb1+u6YWa23Mzeq3w/vLFjAsiqP0/jfy9pz3/eb5G0wt2Pk7Si8jOAFlaz7O7+qqRP97j6EkkLK5cXSpqS71gA8lbvC3RHunuXJFW+H1HthmY23czKZlbu7u6u8+4AZNXwV+PdfZ67l9y91NbW1ui7A1BFvWXfambtklT5vi2/kQA0Qr1lf1bS7jVvp0l6Jp9xADRKzePsZrZI0kRJw81ss6TbJM2R9Eczu0bSJkm/bOSQaF3ffPNNMr/77rurZg8//HBy2w0bNiTzwYMHJ/OTTjqpavbcc88ltx06dGgy3xfVLLu7T60SnZXzLAAaiLfLAkFQdiAIyg4EQdmBICg7EAQfcc3B119/ncxrHWLauXNnnuN8T3t7ezLv6upK5ps2bUrmS5curXv78847L7ntQw89lMzHjRuXzIcPH57Mo2HPDgRB2YEgKDsQBGUHgqDsQBCUHQiCsgNBcJw9B8uXL0/mqY95StIHH3yQ5zi5GjlyZDK/9dZbk/mZZ55ZNRs9enRdM6E+7NmBICg7EARlB4Kg7EAQlB0IgrIDQVB2IAiOs+fgoosuSuZnnZU+Ee+2bcWtsbFgwYJk/uSTTybzxx9/PJmfeuqpez0TGoM9OxAEZQeCoOxAEJQdCIKyA0FQdiAIyg4EYe7etDsrlUpeLpebdn/I7ttvv03mc+fOTeZz5sypmtU6Bv/EE08k8wEDBiTziEqlksrlsvWV1dyzm9kCM9tmZut6XXe7mX1sZp2Vr/PzHBhA/vrzNP73kib1cf3v3H1c5WtZvmMByFvNsrv7q5I+bcIsABooywt0M83srcrT/MOr3cjMpptZ2czK3d3dGe4OQBb1ln2upFGSxknqkvTbajd093nuXnL3UltbW513ByCrusru7lvd/Tt33yVpvqTx+Y4FIG91ld3Meq8D/AtJ66rdFkBrqPl5djNbJGmipOFmtlnSbZImmtk4SS5po6TrGjdic7z55pvJfMSIEVWzYcOG5T1Oyxg4cGAyv+GGG5J5ag32s88+O7ntySefnMxrfdZ+1KhRyTyammV396l9XP1IA2YB0EC8XRYIgrIDQVB2IAjKDgRB2YEgwpxKutbpms8555xk/sorr1TN9udDb1mNGTOmarZ48eLkttdee20yTy0HLUkvvfRS1ez4449Pbrs/Ys8OBEHZgSAoOxAEZQeCoOxAEJQdCIKyA0GEOc6+bFn6nJgXXnhhMh87dmye40DSKaecksxr/X+W+visJM2YMaNqtnTp0uS2Bx98cDLfF7FnB4Kg7EAQlB0IgrIDQVB2IAjKDgRB2YEgwhxnr+Wwww4regTsYeTIkcl89uzZyfyyyy6rmq1atSq5ba3TXO+L2LMDQVB2IAjKDgRB2YEgKDsQBGUHgqDsQBD9WbJ5hKRHJR0laZekee5+r5kNk/SEpA71LNv8K3f/n8aNmk17e3syf/DBB5P5jh07qmZDhw6tayZkM2XKlGSeOmf9U089ldw26nH2nZJ+4+4/kXSKpOvNbKykWyStcPfjJK2o/AygRdUsu7t3ufvayuUvJL0r6WhJl0haWLnZQklTGjQjgBzs1d/sZtYh6WeSXpd0pLt3ST3/IEg6IvfpAOSm32U3syGSnpL0a3f/fC+2m25mZTMrd3d31zMjgBz0q+xmNkA9RX/c3f9UuXqrmbVX8nZJfa6c6O7z3L3k7qW2trY8ZgZQh5plNzOT9Iikd9397l7Rs5KmVS5Pk/RM/uMByEt/PuJ6uqQrJb1tZp2V62ZJmiPpj2Z2jaRNkn7ZkAlzcsYZZyTzjz76KJm/8MILVbNLL700ue0BB/B2hkYYOHBgMj/qqKOqZqtXr857nJZXs+zuvlKSVYnPynccAI3CLgcIgrIDQVB2IAjKDgRB2YEgKDsQRJhTSR9yyCHJ/M4770zmV111VdVs/fr1yW1nzZqVzAcNGpTM0be77rormXd2dlbNbrvttpynaX3s2YEgKDsQBGUHgqDsQBCUHQiCsgNBUHYgiDDH2Wu58sork7m7V82mT5+e3HbJkiXJfM6cOcm81mfxhwwZksxb1TvvvJPM586dm8xrnf775ptvrppdd911yW33R+zZgSAoOxAEZQeCoOxAEJQdCIKyA0FQdiAIjrP3U+rz7CeeeGJy23vuuSeZ33TTTcn8s88+S+aTJ0+umtU6p32tz/lv2rQpma9atSqZv/jii1Wzjz/+OLntqFGjkvkDDzyQzGfMmJHMo2HPDgRB2YEgKDsQBGUHgqDsQBCUHQiCsgNBWOpz2pJkZiMkPSrpKEm7JM1z93vN7HZJ/yipu3LTWe6+LPW7SqWSl8vlzEPvb7766qtkXuuc9q+99lrVbN26dcltax1n//DDD5N5rc/aT5gwoWp22mmnJbc999xzk3mt9dkjKpVKKpfLfS6x3p831eyU9Bt3X2tmP5K0xsyWV7Lfufu/5jUogMapWXZ375LUVbn8hZm9K+noRg8GIF979Te7mXVI+pmk1ytXzTSzt8xsgZkdXmWb6WZWNrNyd3d3XzcB0AT9LruZDZH0lKRfu/vnkuZKGiVpnHr2/L/tazt3n+fuJXcvtbW1ZZ8YQF36VXYzG6Ceoj/u7n+SJHff6u7fufsuSfMljW/cmACyqll2MzNJj0h6193v7nV9e6+b/UJS+mVfAIXqz6vxp0u6UtLbZtZZuW6WpKlmNk6SS9ooKd65eXMyePDgZD579uwmTYL9WX9ejV8pqa/jdslj6gBaC++gA4Kg7EAQlB0IgrIDQVB2IAjKDgRB2YEgKDsQBGUHgqDsQBCUHQiCsgNBUHYgCMoOBFHzVNK53plZt6Te5yYeLml70wbYO606W6vOJTFbvfKc7W/dvc/zvzW17D+4c7Oyu5cKGyChVWdr1bkkZqtXs2bjaTwQBGUHgii67PMKvv+UVp2tVeeSmK1eTZmt0L/ZATRP0Xt2AE1C2YEgCim7mU0ys/8ys/fN7JYiZqjGzDaa2dtm1mlmha4vXVlDb5uZret13TAzW25m71W+97nGXkGz3W5mH1ceu04zO7+g2UaY2ctm9q6ZrTezGyrXF/rYJeZqyuPW9L/ZzexASX+RdI6kzZLekDTV3d9p6iBVmNlGSSV3L/wNGGb2c0lfSnrU3U+oXHenpE/dfU7lH8rD3f2fWmS22yV9WfQy3pXVitp7LzMuaYqkf1CBj11irl+pCY9bEXv28ZLed/cN7v6tpD9IuqSAOVqeu78q6dM9rr5E0sLK5YXq+Y+l6arM1hLcvcvd11YufyFp9zLjhT52ibmaooiyHy3po14/b1Zrrffukl40szVmNr3oYfpwpLt3ST3/8Ug6ouB59lRzGe9m2mOZ8ZZ57OpZ/jyrIsre11JSrXT873R3P0nSZEnXV56uon/6tYx3s/SxzHhLqHf586yKKPtmSSN6/XyMpC0FzNEnd99S+b5N0tNqvaWot+5eQbfyfVvB8/y/VlrGu69lxtUCj12Ry58XUfY3JB1nZj82s4GSLpf0bAFz/ICZDa68cCIzGyzpXLXeUtTPSppWuTxN0jMFzvI9rbKMd7VlxlXwY1f48ufu3vQvSeer5xX5/5b0z0XMUGWuv5P0ZuVrfdGzSVqknqd1f1XPM6JrJP2NpBWS3qt8H9ZCs/27pLclvaWeYrUXNNsE9fxp+JakzsrX+UU/dom5mvK48XZZIAjeQQcEQdmBICg7EARlB4Kg7EAQlB0IgrIDQfwfuaO8OmCCxkQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Visualize the input data. Change the index value to visualize the particular index data.\n",
    "index=7;\n",
    "plt.title((train_labels[index]))\n",
    "plt.imshow(train_data[index].reshape(28,28), cmap=cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data\n",
      "occurance of  0 = 4132\n",
      "occurance of  1 = 4684\n",
      "occurance of  2 = 4177\n",
      "occurance of  3 = 4351\n",
      "occurance of  4 = 4072\n",
      "occurance of  5 = 3795\n",
      "occurance of  6 = 4137\n",
      "occurance of  7 = 4401\n",
      "occurance of  8 = 4063\n",
      "occurance of  9 = 4188\n"
     ]
    }
   ],
   "source": [
    "print(\"train data\")\n",
    "y_value=np.zeros((1,10))\n",
    "for i in range (10):\n",
    "    print(\"occurance of \",i,\"=\",np.count_nonzero(train_labels==i))\n",
    "    y_value[0,i-1]= np.count_nonzero(train_labels==i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_value=y_value.ravel()\n",
    "x_value=[0,1,2,3,4,5,6,7,8,9]\n",
    "plt.xlabel('label')\n",
    "plt.ylabel('count')\n",
    "plt.bar(x_value,y_value,0.7,color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data shape=(784, 42000)\n",
      "train_label shape=(10, 42000)\n"
     ]
    }
   ],
   "source": [
    "#converting train_label in one hot encoder representation \n",
    "train_data=np.reshape(train_data,[784,42000])\n",
    "train_label=np.zeros((10,42000))\n",
    "for col in range (42000):\n",
    "    val=train_labels[col]\n",
    "    for row in range (10):\n",
    "        if (val==row):\n",
    "            train_label[val,col]=1\n",
    "print(\"train_data shape=\"+str(np.shape(train_data)))\n",
    "print(\"train_label shape=\"+str(np.shape(train_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    cache = Z\n",
    "    return A, cache\n",
    "\n",
    "def relu(Z):\n",
    "    A = np.maximum(0,Z)    \n",
    "    cache = Z \n",
    "    return A, cache\n",
    "\n",
    "def softmax(Z):\n",
    "    e_x = np.exp(Z)\n",
    "    A= e_x / np.sum(np.exp(Z))  \n",
    "    cache=Z\n",
    "    return A,cache   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dA, cache):\n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True)\n",
    "    dZ[Z <= 0] = 0\n",
    "    assert (dZ.shape == Z.shape)\n",
    "    return dZ\n",
    "\n",
    "def sigmoid_backward(dA, cache):    \n",
    "    Z = cache\n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    assert (dZ.shape == Z.shape)\n",
    "    return dZ\n",
    "\n",
    "def softmax_backward(Z,cache):\n",
    "    Z=cache\n",
    "    length=10  \n",
    "    dZ=np.zeros((42000,10))\n",
    "    Z=np.transpose(Z)\n",
    "    for row in range (0,42000):\n",
    "            den=(np.sum(np.exp(Z[row,:])))*(np.sum(np.exp(Z[row,:])))\n",
    "            for col in range (0,10):\n",
    "                sums=0\n",
    "                for j in range (0,10):\n",
    "                    if (j!=col):\n",
    "                        sums=sums+(math.exp(Z[row,j]))\n",
    "                \n",
    "                dZ[row,col]=(math.exp(Z[row,col])*sums)/den           \n",
    "    dZ=np.transpose(dZ)\n",
    "    Z=np.transpose(Z)\n",
    "\n",
    "    assert (dZ.shape == Z.shape)\n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initializing the parameters weights and bias\n",
    "def initialize_parameters_deep(layer_dims):\n",
    "    #np.random.seed(1)\n",
    "    parameters = {}\n",
    "    L = len(layer_dims)            # number of layers in the network\n",
    "    \n",
    "    for l in range(1, L):\n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l], layer_dims[l-1]) / np.sqrt(layer_dims[l-1]) #*0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l], 1))\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forward propagation\n",
    "def linear_forward(A, W, b):\n",
    "    Z = np.dot(W,A) +b\n",
    "    cache = (A, W, b)\n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    return Z, cache\n",
    "\n",
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    if activation == \"sigmoid\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    elif activation == \"relu\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        #print(\"Z=\"+str(Z))\n",
    "        A, activation_cache = relu(Z) \n",
    "    elif activation == \"softmax\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = softmax(Z)\n",
    "    cache = (linear_cache, activation_cache)\n",
    "    return A, cache\n",
    "\n",
    "def L_model_forward(X, parameters):\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2                  # number of layers in the neural network\n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], activation = \"relu\")\n",
    "        caches.append(cache)\n",
    "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], activation = \"softmax\")\n",
    "    caches.append(cache)               \n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cost function\n",
    "def compute_cost(AL, Y):\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "    cost = (-1 / m) * np.sum(np.multiply(Y, np.log(AL)) + np.multiply(1 - Y, np.log(1 - AL)))\n",
    "    #print(\"cost=\"+str(cost))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#backward propagation\n",
    "def linear_backward(dZ, cache):\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    dW = 1./m * np.dot(dZ,A_prev.T)  \n",
    "    db = (1/m)*np.sum(dZ, axis=1, keepdims=True);\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    return dA_prev, dW, db\n",
    "\n",
    "def linear_activation_backward(dA, cache, activation):\n",
    "    linear_cache, activation_cache = cache\n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)  \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    elif activation == \"softmax\":\n",
    "        dZ = softmax_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    return dA_prev, dW, db\n",
    "\n",
    "def L_model_backward(AL, Y, caches):\n",
    "    grads = {}\n",
    "    L = len(caches) # the number of layers\n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL))\n",
    "    M=len(layers_dims)\n",
    "    current_cache = caches[M-2]\n",
    "    grads[\"dA\"+str(M-1)], grads[\"dW\"+str(M-1)], grads[\"db\"+str(M-1)] = linear_activation_backward(dAL, current_cache, activation = \"softmax\")#M-1\n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 2)], current_cache, activation = \"relu\")\n",
    "        grads[\"dA\" + str(l + 1)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upgrade function for weights and bias\n",
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    for l in range(len_update-1):\n",
    "        parameters[\"W\" + str(l+1)] =parameters[\"W\" + str(l+1)] - (learning_rate*grads[\"dW\" + str(l+1)])\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)] - (learning_rate*grads[\"db\" + str(l+1)])\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(cost_plot):\n",
    "       \n",
    "    x_value=list(range(1,len(cost_plot)+1))\n",
    "    #print(x_value)\n",
    "    #print(cost_plot)\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('cost')\n",
    "    plt.plot(x_value,cost_plot,0.,color='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining structure of neural network\n",
    "layers_dims = [784,500,400,300,100,10] #  n-layer model (n=6 including input and output layer)\n",
    "len_update=len(layers_dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to call sub_functions\n",
    "def L_layer_model(X, Y, layers_dims, learning_rate , num_iterations , print_cost=False):#lr was 0.009\n",
    "    print(\"training...\")\n",
    "    costs = []  \n",
    "    cost_plot=np.zeros(num_iterations)\n",
    "    parameters = initialize_parameters_deep(layers_dims)\n",
    "    for i in range(0, num_iterations):\n",
    "        AL, caches = L_model_forward(X, parameters)\n",
    "        cost =compute_cost(AL, Y)\n",
    "        grads = L_model_backward(AL, Y, caches)\n",
    "        parameters = update_parameters(parameters, grads, learning_rate) \n",
    "        cost_plot[i]=cost;\n",
    "    \n",
    "    plot_graph(cost_plot)\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n"
     ]
    }
   ],
   "source": [
    "#variable parameter in network learning_rate, iterationd \n",
    "parameters = L_layer_model(train_data, train_label, layers_dims,learning_rate = 0.0005, num_iterations =35 , print_cost = True) \n",
    "print(\"training done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
